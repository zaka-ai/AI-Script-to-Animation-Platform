{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ae9e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install gradio --quiet\n",
    "!pip install edge_tts\n",
    "\n",
    "import gradio as gr\n",
    "import asyncio\n",
    "import os\n",
    "import traceback\n",
    "import numpy as np\n",
    "import re\n",
    "import base64\n",
    "from functools import partial\n",
    "\n",
    "# Import all required libraries from your original code\n",
    "import torch\n",
    "import imageio\n",
    "import cv2\n",
    "from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "from PIL import Image\n",
    "import edge_tts\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "\n",
    "# Initialize the Qwen model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "text_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Initialize video generation components\n",
    "device = \"cuda\"\n",
    "dtype = torch.float16\n",
    "step = 8\n",
    "repo = \"ByteDance/AnimateDiff-Lightning\"\n",
    "ckpt = f\"animatediff_lightning_{step}step_diffusers.safetensors\"\n",
    "base = \"emilianJR/epiCRealism\"\n",
    "\n",
    "# Load motion adapter\n",
    "adapter = MotionAdapter().to(device, dtype)\n",
    "adapter.load_state_dict(load_file(hf_hub_download(repo, ckpt), device=device))\n",
    "\n",
    "# Load pipeline\n",
    "pipe = AnimateDiffPipeline.from_pretrained(base, motion_adapter=adapter, torch_dtype=dtype).to(device)\n",
    "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", beta_schedule=\"linear\")\n",
    "\n",
    "# Define all required functions from your original code\n",
    "def summarize(text):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an expert summarizer focused on efficiency and clarity. \"\n",
    "                \"Create concise narrative summaries that: \"\n",
    "                \"1. Capture all key points and main ideas \"\n",
    "                \"2. Omit examples, repetitions, and secondary details \"\n",
    "                \"3. Maintain logical flow and coherence \"\n",
    "                \"4. Use clear, direct language without markdown formatting\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Please summarize the following text in 10-15 sentences. \"\n",
    "                \"Focus on essential information, exclude non-critical details, \"\n",
    "                f\"and maintain natural storytelling flow:\\n\\n{text}\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    response = text_pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=512,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    result = response[0]['generated_text']\n",
    "    summary = result.split(\"assistant\\n\")[-1].strip()\n",
    "    return summary\n",
    "\n",
    "def generate_story(prompt):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a skilled storyteller specializing in tight, impactful narratives. \"\n",
    "                \"Create engaging stories that:\\n\"\n",
    "                \"1. Contain exactly 15-20 sentences\\n\"\n",
    "                \"2. Keep each sentence under 77 tokens\\n\"\n",
    "                \"3. Maintain strong narrative flow and pacing\\n\"\n",
    "                \"4. Focus on vivid imagery and concrete details\\n\"\n",
    "                \"5. Avoid filler words and redundant phrases\\n\"\n",
    "                \"6. Use simple, direct language without markdown\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"Craft a compelling short story based on this premise: {prompt}\\n\"\n",
    "                \"Structure requirements:\\n\"\n",
    "                \"- Strict 15-20 sentence count\\n\"\n",
    "                \"- Maximum 77 tokens per sentence\\n\"\n",
    "                \"- Clear beginning-middle-end structure\\n\"\n",
    "                \"- Emphasis on showing rather than telling\\n\"\n",
    "                \"Output plain text only, no markdown formatting.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    chat_prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # First attempt to generate story\n",
    "    generated = text_pipe(\n",
    "        chat_prompt,\n",
    "        max_new_tokens=1024,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=4,\n",
    "        temperature=0.65,\n",
    "        top_k=30,\n",
    "        top_p=0.90,\n",
    "        do_sample=True,\n",
    "        length_penalty=0.9\n",
    "    )\n",
    "\n",
    "    full_output = generated[0]['generated_text']\n",
    "    story = full_output.split(\"assistant\\n\")[-1].strip()\n",
    "\n",
    "    # Process sentences and check constraints\n",
    "    sentences = []\n",
    "    for s in story.split('.'):\n",
    "        if s.strip():\n",
    "            sentences.append(s.strip())\n",
    "\n",
    "    # Check sentence count constraint\n",
    "    sentence_count = len(sentences)\n",
    "    if sentence_count < 15 or sentence_count > 20:\n",
    "        # Regenerate with stricter parameters if constraints not met\n",
    "        enhanced_prompt = f\"{prompt} (IMPORTANT: Story MUST have EXACTLY 15-20 sentences, and each sentence MUST be under 77 tokens. Current attempt had {sentence_count} sentences.)\"\n",
    "\n",
    "        messages[1][\"content\"] = (\n",
    "            f\"Craft a compelling short story based on this premise: {enhanced_prompt}\\n\"\n",
    "            \"Structure requirements:\\n\"\n",
    "            \"- CRITICAL: Output EXACTLY 15-20 sentences, not more, not less\\n\"\n",
    "            \"- CRITICAL: Maximum 77 tokens per sentence\\n\"\n",
    "            \"- Clear beginning-middle-end structure\\n\"\n",
    "            \"- Emphasis on showing rather than telling\\n\"\n",
    "            \"Output plain text only, no markdown formatting.\"\n",
    "        )\n",
    "\n",
    "        chat_prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        # Try with more strict parameters\n",
    "        generated = text_pipe(\n",
    "            chat_prompt,\n",
    "            max_new_tokens=1024,\n",
    "            num_beams=7,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=4,\n",
    "            temperature=0.5,\n",
    "            top_k=20,\n",
    "            top_p=0.85,\n",
    "            do_sample=True,\n",
    "            length_penalty=1.0\n",
    "        )\n",
    "\n",
    "        full_output = generated[0]['generated_text']\n",
    "        story = full_output.split(\"assistant\\n\")[-1].strip()\n",
    "\n",
    "        sentences = []\n",
    "        for s in story.split('.'):\n",
    "            if s.strip():\n",
    "                sentences.append(s.strip())\n",
    "\n",
    "    word_to_token_ratio = 1.3\n",
    "    constrained_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        estimated_tokens = len(words) * word_to_token_ratio\n",
    "\n",
    "        if estimated_tokens > 77:\n",
    "            max_words = int(75 / word_to_token_ratio)\n",
    "            truncated = ' '.join(words[:max_words])\n",
    "            constrained_sentences.append(truncated)\n",
    "        else:\n",
    "            constrained_sentences.append(sentence)\n",
    "\n",
    "    while len(constrained_sentences) < 15:\n",
    "        constrained_sentences.append(\"The story continued with unexpected twists and turns.\")\n",
    "    constrained_sentences = constrained_sentences[:20]\n",
    "\n",
    "    formatted_sentences = []\n",
    "    for s in constrained_sentences:\n",
    "        if not s.endswith(('.', '!', '?')):\n",
    "            s += '.'\n",
    "        formatted_sentences.append(s)\n",
    "\n",
    "    final_story = '\\n'.join(formatted_sentences)\n",
    "    return final_story\n",
    "\n",
    "def generate_video(summary):\n",
    "    def crossfade_transition(frames1, frames2, transition_length=10):\n",
    "        blended_frames = []\n",
    "        frames1_np = [np.array(frame) for frame in frames1[-transition_length:]]\n",
    "        frames2_np = [np.array(frame) for frame in frames2[:transition_length]]\n",
    "        for i in range(transition_length):\n",
    "            alpha = i / transition_length\n",
    "            beta = 1.0 - alpha\n",
    "            blended = cv2.addWeighted(frames1_np[i], beta, frames2_np[i], alpha, 0)\n",
    "            blended_frames.append(Image.fromarray(blended))\n",
    "        return blended_frames\n",
    "\n",
    "    # Sentence splitting\n",
    "    sentences = []\n",
    "    current_sentence = \"\"\n",
    "    for char in summary:\n",
    "        current_sentence += char\n",
    "        if char in {'.', '!', '?'}:\n",
    "            sentences.append(current_sentence.strip())\n",
    "            current_sentence = \"\"\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    print(f\"Total scenes: {len(sentences)}\")\n",
    "\n",
    "    # Output config\n",
    "    output_dir = \"generated_frames\"\n",
    "    video_path = \"generated_video.mp4\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Generate animation\n",
    "    all_frames = []\n",
    "    previous_frames = None\n",
    "    transition_frames = 10\n",
    "    batch_size = 1\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_prompts = sentences[i : i + batch_size]\n",
    "        for idx, prompt in enumerate(batch_prompts):\n",
    "            print(f\"Generating animation for prompt {i+idx+1}/{len(sentences)}: {prompt}\")\n",
    "            output = pipe(\n",
    "                prompt=prompt,\n",
    "                guidance_scale=1.0,\n",
    "                num_inference_steps=step,\n",
    "                width=256,\n",
    "                height=256,\n",
    "            )\n",
    "            frames = output.frames[0]\n",
    "\n",
    "            if previous_frames is not None:\n",
    "                transition = crossfade_transition(previous_frames, frames, transition_frames)\n",
    "                all_frames.extend(transition)\n",
    "\n",
    "            all_frames.extend(frames)\n",
    "            previous_frames = frames\n",
    "\n",
    "    # Save video\n",
    "    imageio.mimsave(video_path, all_frames, fps=8)\n",
    "    print(f\"Video saved at {video_path}\")\n",
    "    return video_path\n",
    "\n",
    "def estimate_voiceover_words(video_path):\n",
    "    try:\n",
    "        # Get video duration in seconds\n",
    "        video = VideoFileClip(video_path)\n",
    "        duration_minutes = video.duration / 60\n",
    "        # Estimate word count based on average speaking rate (150 words per minute)\n",
    "        estimated_words = int(duration_minutes * 150)\n",
    "        # Ensure a minimum word count\n",
    "        return max(estimated_words, 30)\n",
    "    except Exception as e:\n",
    "        print(f\"Error estimating voiceover words: {str(e)}\")\n",
    "        return 50  # Default fallback\n",
    "\n",
    "def summary_of_summary(text, video_path):\n",
    "    target_word_count = estimate_voiceover_words(video_path)\n",
    "    messages_2 = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an expert summarizer focused on brevity and clarity. \"\n",
    "                f\"Create a summary that is exactly around {target_word_count} words: \"\n",
    "                \"1. Capture the most essential information\\n\"\n",
    "                \"2. Omit unnecessary details and examples\\n\"\n",
    "                \"3. Maintain logical flow and coherence\\n\"\n",
    "                \"4. Use clear, direct language\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"Please summarize the following text in approximately {target_word_count} words:\\n\\n{text}\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Generate prompt\n",
    "    prompt_for_resummarization = tokenizer.apply_chat_template(\n",
    "        messages_2,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # Generate response\n",
    "    response = text_pipe(\n",
    "        prompt_for_resummarization,\n",
    "        max_new_tokens=target_word_count + 20,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    # Extract result\n",
    "    summary = response[0]['generated_text'].split(\"assistant\\n\")[-1].strip()\n",
    "    return summary\n",
    "\n",
    "async def generate_audio_with_sentiment(text, sentiment_analyzer):\n",
    "    # Perform sentiment analysis on the text\n",
    "    sentiment = sentiment_analyzer(text)[0]\n",
    "    label = sentiment['label']\n",
    "    confidence = sentiment['score']\n",
    "\n",
    "    print(f\"Sentiment: {label} with confidence {confidence:.2f}\")\n",
    "\n",
    "    # Set voice parameters based on sentiment\n",
    "    if label == \"POSITIVE\":\n",
    "        voice = \"en-US-AriaNeural\"  # Cheerful and energetic tone for positive sentiment\n",
    "        rate = \"1.2\"  # Faster speech\n",
    "        pitch = \"+2Hz\"  # Slightly higher pitch for a more positive tone\n",
    "    else:\n",
    "        voice = \"en-US-GuyNeural\"  # Neutral tone for negative sentiment\n",
    "        rate = \"0.9\"  # Slower speech\n",
    "        pitch = \"-2Hz\"  # Lower pitch for a more somber tone\n",
    "\n",
    "    # Generate speech with EdgeTTS\n",
    "    communicate = edge_tts.Communicate(text, voice)\n",
    "\n",
    "    # Save the audio to a file\n",
    "    await communicate.save(\"output.mp3\")\n",
    "\n",
    "    # Play the generated audio\n",
    "    return \"output.mp3\"\n",
    "\n",
    "def combine_video_with_audio(video_path, audio_path, output_path):\n",
    "    # Load video and audio\n",
    "    video = VideoFileClip(video_path)\n",
    "    audio = AudioFileClip(audio_path)\n",
    "\n",
    "    # Set the audio to the video\n",
    "    video = video.set_audio(audio)\n",
    "\n",
    "    # Save the final video\n",
    "    video.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "    print(\"Video with audio saved successfully!\")\n",
    "\n",
    "# Function to create a download link for the video file\n",
    "def get_file_download_link(file_path):\n",
    "    \"\"\"\n",
    "    Create an HTML link to download a file directly from the Gradio interface\n",
    "    or return the file path for API usage\n",
    "    \"\"\"\n",
    "    # If the file exists, create a download link\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            file_content = file.read()\n",
    "            b64_content = base64.b64encode(file_content).decode()\n",
    "            \n",
    "            # Create a download link\n",
    "            download_link = f'<a href=\"data:video/mp4;base64,{b64_content}\" download=\"{os.path.basename(file_path)}\">Click here to download the video</a>'\n",
    "            return download_link\n",
    "    else:\n",
    "        return \"File not found\"\n",
    "\n",
    "# Main processing function\n",
    "def create_story_video(prompt, progress=gr.Progress()):\n",
    "    # Input validation\n",
    "    if not prompt or len(prompt.strip()) < 5:\n",
    "        return \"Please enter a longer prompt (at least 5 characters).\", None, None, None, None\n",
    "\n",
    "    try:\n",
    "        # Step 1: Generate story\n",
    "        progress(0, desc=\"Starting story generation...\")\n",
    "        story = generate_story(prompt)\n",
    "        progress(0.2, desc=\"Story generated successfully!\")\n",
    "\n",
    "        # Step 2: Generate video\n",
    "        progress(0.25, desc=\"Creating video animation (this may take several minutes)...\")\n",
    "        video_path = generate_video(story)\n",
    "        progress(0.60, desc=\"Video created successfully!\")\n",
    "\n",
    "        # Step 3: Create audio summary\n",
    "        progress(0.65, desc=\"Creating audio summary...\")\n",
    "        audio_summary = summary_of_summary(story, video_path)\n",
    "        progress(0.80, desc=\"Creating audio narration...\")\n",
    "\n",
    "        # Step 4: Generate audio with sentiment (async)\n",
    "        try:\n",
    "            # Set up event loop handling\n",
    "            try:\n",
    "                loop = asyncio.get_event_loop()\n",
    "            except RuntimeError:\n",
    "                loop = asyncio.new_event_loop()\n",
    "                asyncio.set_event_loop(loop)\n",
    "\n",
    "            audio_file = loop.run_until_complete(\n",
    "                generate_audio_with_sentiment(audio_summary, sentiment_analyzer)\n",
    "            )\n",
    "            progress(0.90, desc=\"Audio created successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Audio generation error: {str(e)}\")\n",
    "            return story, None, f\"Audio generation failed: {str(e)}\", None, None\n",
    "\n",
    "        # Step 5: Combine video and audio\n",
    "        progress(0.95, desc=\"Combining video and audio...\")\n",
    "        output_path = 'final_video_with_audio.mp4'\n",
    "        combine_video_with_audio(video_path, audio_file, output_path)\n",
    "\n",
    "        progress(1, desc=\"Process complete!\")\n",
    "        \n",
    "        # Create download link for the final video\n",
    "        download_link = get_file_download_link(output_path)\n",
    "        \n",
    "        # Return 5 values as expected by the interface\n",
    "        return story, output_path, audio_summary, download_link, output_path\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error: {str(e)}\\n{traceback.format_exc()}\"\n",
    "        print(error_msg)\n",
    "        return f\"An error occurred: {str(e)}\", None, None, None, None\n",
    "\n",
    "# Function to set example prompt in textbox\n",
    "def set_example_prompt(example):\n",
    "    return example\n",
    "\n",
    "# Sample prompt examples based on realistic scenarios\n",
    "EXAMPLE_PROMPTS = [\n",
    "    \"A nurse discovers an unusual pattern in patient symptoms that leads to an important medical breakthrough.\",\n",
    "    \"During a home renovation, a family uncovers a time capsule from the previous owners.\",\n",
    "    \"A struggling local restaurant owner finds an innovative way to save their business during an economic downturn.\",\n",
    "    \"An environmental scientist tracks mysterious wildlife behavior that reveals concerning climate changes.\",\n",
    "    \"A community comes together to rebuild after a devastating natural disaster.\",\n",
    "    \"A teacher develops a unique method that transforms learning for students with special needs.\",\n",
    "    \"An elderly person reconnects with a childhood friend through social media after sixty years apart.\",\n",
    "    \"A food delivery driver forms an unexpected friendship with an isolated elderly customer during the pandemic.\",\n",
    "    \"A first-generation college student overcomes significant obstacles to achieve academic success.\",\n",
    "    \"A wildlife photographer documents the surprising recovery of an endangered species.\"\n",
    "]\n",
    "\n",
    "# Handle clearing\n",
    "def clear_outputs():\n",
    "    return \"\", None, \"\", \"\", None\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks(title=\"Animind AI Story Video Generator\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# 🎬 AI Story Video Generator\")\n",
    "    gr.Markdown(\"Enter a one-sentence prompt to generate a complete story with video and narration.\")\n",
    "\n",
    "    # Input section\n",
    "    with gr.Row():\n",
    "        prompt_input = gr.Textbox(\n",
    "            label=\"Your Story Idea\",\n",
    "            placeholder=\"Enter a one-sentence prompt (e.g., 'A detective discovers a hidden room in an abandoned mansion')\",\n",
    "            lines=2\n",
    "        )\n",
    "\n",
    "    # Example prompts section\n",
    "    gr.Markdown(\"### Try these example prompts:\")\n",
    "\n",
    "    # Create examples using Gradio's examples feature\n",
    "    with gr.Row():\n",
    "        examples = gr.Examples(\n",
    "            examples=[[prompt] for prompt in EXAMPLE_PROMPTS],\n",
    "            inputs=prompt_input,\n",
    "            label=\"Click any example to load it\"\n",
    "        )\n",
    "\n",
    "    with gr.Row():\n",
    "        generate_button = gr.Button(\"Generate Story Video\", variant=\"primary\")\n",
    "        clear_button = gr.Button(\"Clear\", variant=\"secondary\")\n",
    "\n",
    "    # Status indicator\n",
    "    status_indicator = gr.Markdown(\"Ready to generate your story video...\")\n",
    "\n",
    "    # Output section with tabs\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Results\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=2):\n",
    "                    video_output = gr.Video(label=\"Generated Video with Narration\")\n",
    "                    download_output = gr.HTML(label=\"Download Video\")  # Added for direct download link\n",
    "                    file_output = gr.File(label=\"Download Video File\")  # Added for file download\n",
    "                with gr.Column(scale=1):\n",
    "                    story_output = gr.TextArea(label=\"Generated Story\", lines=15, max_lines=30)\n",
    "                    summary_output = gr.TextArea(label=\"Audio Summary\", lines=5)\n",
    "\n",
    "        with gr.TabItem(\"Help & Information\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ## How to use this tool\n",
    "\n",
    "            1. Enter a creative one-sentence story idea in the input box\n",
    "            2. Click \"Generate Story Video\" and wait for processing to complete\n",
    "            3. View your complete AI-generated story video with narration\n",
    "            4. Download your video using the download link or file download option\n",
    "\n",
    "            ## Processing Steps\n",
    "\n",
    "            1. **Story Generation**: The AI expands your idea into a 15-20 sentence story\n",
    "            2. **Video Creation**: Each sentence is visualized through AI-generated animation\n",
    "            3. **Audio Narration**: The AI analyzes the sentiment and creates appropriate voiceover\n",
    "            4. **Final Compilation**: Video and audio are combined into your final story\n",
    "\n",
    "            ## Tips for Great Results\n",
    "\n",
    "            - Use clear, specific prompts that suggest a narrative arc\n",
    "            - Include interesting characters, settings, or situations\n",
    "            - Make your prompt realistic but with potential for development\n",
    "            - Try to suggest a potential conflict or discovery\n",
    "\n",
    "            ## API Usage\n",
    "\n",
    "            When using this tool via API, you'll receive:\n",
    "            1. The generated story text\n",
    "            2. The video path\n",
    "            3. The audio summary\n",
    "            4. A download link (HTML)\n",
    "            5. The file path for direct download\n",
    "\n",
    "            ## Troubleshooting\n",
    "\n",
    "            If you encounter errors:\n",
    "            - Try a different prompt\n",
    "            - Ensure your prompt is clear and specific\n",
    "            - Check that all required models are properly loaded\n",
    "            \"\"\")\n",
    "\n",
    "    # Connect interface elements with the updated function\n",
    "    generate_button.click(\n",
    "        fn=create_story_video,  # Use the updated function with 5 return values\n",
    "        inputs=prompt_input,\n",
    "        outputs=[story_output, video_output, summary_output, download_output, file_output],\n",
    "        api_name=\"generate\"\n",
    "    )\n",
    "\n",
    "    clear_button.click(\n",
    "        fn=clear_outputs,\n",
    "        inputs=None,\n",
    "        outputs=[story_output, video_output, summary_output, download_output, file_output]\n",
    "    )\n",
    "\n",
    "# Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
